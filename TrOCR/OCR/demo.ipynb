{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06fb46e-de31-4f5c-8bdb-42375ee10f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Application to provide benchmark timers for code. \n",
    "Usage: \n",
    "# from my_timer_class import MyTimer\n",
    "from my_timer_func import my_timer\n",
    "import time\n",
    "\n",
    "@MyTimer3(name=\"decorator\")\n",
    "@my_timer\n",
    "\"\"\"\n",
    "\n",
    "import functools\n",
    "import time\n",
    "\n",
    "def my_timer(orig_func):\n",
    "    import time\n",
    "    @functools.wraps(orig_func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        tic = time.perf_counter()\n",
    "        value = orig_func(*args, **kwargs)\n",
    "        toc = time.perf_counter()\n",
    "        elapsed_time = toc - tic\n",
    "        print(f\"Elapsed time to run {orig_func.__name__}: {elapsed_time:0.4f} seconds\")\n",
    "        return value\n",
    "    return wrapper_timer\n",
    "\n",
    "\n",
    "class MyTimer():\n",
    "    # usage:\n",
    "    #\n",
    "    # from MyTimer import MyTimer\n",
    "    # with MyTimer():\n",
    "    #    func(x,y)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "        self.start_p = time.perf_counter()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        end = time.time()\n",
    "        end_p = time.perf_counter()\n",
    "        runtime = end - self.start\n",
    "        runtime_p = end_p - self.start_p\n",
    "        msg = 'The function took {time} seconds to complete'\n",
    "        print(msg.format(time=runtime))\n",
    "        msg_p = 'The function took {time} perf seconds to complete'\n",
    "        print(msg_p.format(time=runtime_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbcd6a8-8e2c-482b-9a81-98b989cd0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "conda env remove --name trOCR\n",
    "conda env create --name trOCR --file environment.yml\n",
    "\n",
    "cache folder\n",
    "C:\\Users\\techexpert\\.cache\\huggingface\\hub\n",
    "\n",
    "nvidia-smi for GPU info\n",
    "\n",
    "cd scripts\n",
    "python trOCR.py\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image \n",
    "import torch\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel \n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "@my_timer\n",
    "# https://huggingface.co/microsoft/trocr-base-handwritten\n",
    "def run_trOCR(model_name=\"microsoft/trocr-base-handwritten\", images=\"\"):\n",
    "    \"\"\"\n",
    "    There are 3 main models to choose from, small, base and large. \n",
    "    Some other fine-tuned models: IAM Handwritten, SROIE Receipts\n",
    "    \"\"\"\n",
    "    processor = TrOCRProcessor.from_pretrained(model_name, use_fast = True)\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "    print(model)\n",
    "\n",
    "    # Check for GPU availability\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"running on {device}\")\n",
    "    model.to(device)  # Move model to GPU\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    generated_ids = model.generate(pixel_values, max_new_tokens=1000)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ff3052-e8b8-463d-abd4-0118160e2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_parameters(model_id = \"microsoft/trocr-base-handwritten\"):\n",
    "    processor  = TrOCRProcessor.from_pretrained(model_id, use_fast = True)\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_id)\n",
    "    encoder_params = 0 \n",
    "    decoder_params = 0 \n",
    "    all_params = 0 \n",
    "    for name, params in model.named_parameters():\n",
    "        numParam = params.numel()\n",
    "        all_params += numParam \n",
    "        if 'encoder' in name: \n",
    "            encoder_params += numParam\n",
    "        elif 'decoder' in name:\n",
    "            decoder_params += numParam\n",
    "    print(f\"Number of parameters: {all_params/1000000}M\")\n",
    "    print(f\"Number of encoder's parameters: {encoder_params/1000000}M\")\n",
    "    print(f\"Number of decoder's parameters: {decoder_params/1000000}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc4cf5ad-e553-4db9-af0f-87dc3676a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 558.226432M\n",
      "Number of encoder's parameters: 355.072M\n",
      "Number of decoder's parameters: 203.154432M\n"
     ]
    }
   ],
   "source": [
    "get_n_parameters(\"microsoft/trocr-large-handwritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8a3edb-6847-4f5b-82f1-18cc4e9937ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderModel(\n",
      "  (encoder): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (pooler): ViTPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder): TrOCRForCausalLM(\n",
      "    (model): TrOCRDecoderWrapper(\n",
      "      (decoder): TrOCRDecoder(\n",
      "        (embed_tokens): TrOCRScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
      "        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 1024)\n",
      "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (layers): ModuleList(\n",
      "          (0-11): 12 x TrOCRDecoderLayer(\n",
      "            (self_attn): TrOCRAttention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (activation_fn): GELUActivation()\n",
      "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): TrOCRAttention(\n",
      "              (k_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=1024, out_features=50265, bias=False)\n",
      "  )\n",
      ")\n",
      "running on cuda\n",
      "mund Macmillan executive American\n",
      "Elapsed time to run run_trOCR: 29.0172 seconds\n"
     ]
    }
   ],
   "source": [
    "model_id = \"microsoft/trocr-base-handwritten\" # indus tre, This is a sample of text\n",
    "\n",
    "link_image = \"datasets/text_recognition_mcocr_data/text_recognition_mcocr_data/mcocr_public_145014qrfai_0.jpg\" # \n",
    "image = Image.open(link_image).convert(\"RGB\")\n",
    "run_trOCR(model_id, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f1844-f3f0-4e01-bd3b-a0ff62f6e608",
   "metadata": {},
   "source": [
    "## Image to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "892050f5-afa5-46fe-8572-6abfbf570df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\n",
      "  Downloading optimum-2.0.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.12/dist-packages (from optimum) (4.55.0)\n",
      "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.12/dist-packages (from optimum) (2.8.0a0+5228986c39.nv25.5)\n",
      "Requirement already satisfied: packaging in /opt/venv/lib/python3.12/site-packages (from optimum) (25.0)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.12/site-packages (from optimum) (1.26.4)\n",
      "Requirement already satisfied: huggingface_hub>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from optimum) (0.34.3)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum) (1.1.6rc1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum) (79.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11->optimum) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/venv/lib/python3.12/site-packages (from transformers>=4.29->optimum) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/venv/lib/python3.12/site-packages (from transformers>=4.29->optimum) (0.21.4.dev0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/venv/lib/python3.12/site-packages (from transformers>=4.29->optimum) (0.6.0rc0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.8.0->optimum) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.8.0->optimum) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.8.0->optimum) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.8.0->optimum) (2025.7.14)\n",
      "Downloading optimum-2.0.0-py3-none-any.whl (162 kB)\n",
      "Installing collected packages: optimum\n",
      "Successfully installed optimum-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d05ed5f5-5d15-4cb8-8a6c-c90acb836a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optimum[onnxruntime] in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
      "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (4.55.0)\n",
      "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (2.8.0a0+5228986c39.nv25.5)\n",
      "Requirement already satisfied: packaging in /opt/venv/lib/python3.12/site-packages (from optimum[onnxruntime]) (25.0)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.12/site-packages (from optimum[onnxruntime]) (1.26.4)\n",
      "Requirement already satisfied: huggingface_hub>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (0.34.3)\n",
      "Collecting optimum-onnx[onnxruntime] (from optimum[onnxruntime])\n",
      "  Downloading optimum_onnx-0.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/venv/lib/python3.12/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (1.1.6rc1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/venv/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime]) (79.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11->optimum[onnxruntime]) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/venv/lib/python3.12/site-packages (from transformers>=4.29->optimum[onnxruntime]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/venv/lib/python3.12/site-packages (from transformers>=4.29->optimum[onnxruntime]) (0.21.4.dev0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/venv/lib/python3.12/site-packages (from transformers>=4.29->optimum[onnxruntime]) (0.6.0rc0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11->optimum[onnxruntime]) (3.0.2)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (1.18.0)\n",
      "Collecting onnxruntime>=1.18.0 (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime])\n",
      "  Downloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime])\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime])\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in /opt/venv/lib/python3.12/site-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (4.25.8)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime])\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (2025.7.14)\n",
      "Downloading optimum_onnx-0.0.1-py3-none-any.whl (192 kB)\n",
      "Downloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m90.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0mm\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime, optimum-onnx\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [optimum-onnx][0m [optimum-onnx]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.9.23 humanfriendly-10.0 onnxruntime-1.23.1 optimum-onnx-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install optimum[onnxruntime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f43d6525-ad72-46e4-aab2-25f5b25f9c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: optimum\n",
      "Version: 2.0.0\n",
      "Summary: Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.\n",
      "Home-page: https://github.com/huggingface/optimum\n",
      "Author: HuggingFace Inc. Special Ops Team\n",
      "Author-email: hardware@huggingface.co\n",
      "License: Apache\n",
      "Location: /usr/local/lib/python3.12/dist-packages\n",
      "Requires: huggingface_hub, numpy, packaging, torch, transformers\n",
      "Required-by: optimum-onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/registration.py:159: OnnxExporterWarning: Symbolic function 'aten::scaled_dot_product_attention' already registered for opset 14. Replacing the existing function with new function. This is unexpected. Please report it on https://github.com/pytorch/pytorch/issues.\n",
      "  warnings.warn(\n",
      "Multiple distributions found for package optimum. Picked distribution: optimum-onnx\n"
     ]
    }
   ],
   "source": [
    "!pip show optimum\n",
    "from optimum.onnxruntime import ORTModelForVision2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52f23ee5-54fa-45f4-a672-d2dab598860f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find any ONNX files with standard file name decoder_model_merged.onnx, files found: [PosixPath('decoder_model.onnx'), PosixPath('encoder_model.onnx')]. Please make sure to pass a `file_name` and/or `subfolder` argument to `from_pretrained` when loading an ONNX file with non-standard file names.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_ids: tensor([[  2,  95, 263, 353, 380, 261, 264, 262, 263, 346, 262, 313, 338, 313,\n",
      "         323, 281, 296, 307, 261, 261, 270, 263, 357, 264, 262, 293, 270, 268,\n",
      "         261, 265, 262, 359, 261, 263, 357, 264, 262, 372, 270, 268, 261, 265,\n",
      "         262, 429, 261, 262, 263, 353, 386, 261, 264, 262, 372, 261, 265, 262,\n",
      "         263, 346, 262, 267, 313, 338, 313, 323, 281, 296, 307, 266, 261, 261,\n",
      "         263, 303,  12, 263, 303, 596, 263, 415, 262, 379, 261, 264, 262, 293,\n",
      "         271, 372, 261, 272, 282, 264, 262, 293, 271, 372, 261, 263, 304, 596,\n",
      "         265, 262, 269, 261, 263, 304,  13,   2],\n",
      "        [  2,  64, 705, 264, 262, 282, 263, 512, 263, 277, 262, 268, 261, 262,\n",
      "         333, 261, 261, 263, 277, 262, 268, 272, 333, 265, 262, 282, 272, 263,\n",
      "         277, 262, 268, 261, 262, 333, 261, 261, 261, 262, 268, 272, 333, 282,\n",
      "         261,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0]]), \n",
      "generated text: ['{ \\\\cal L } _ { \\\\mathrm { e y e l i d \\\\, } } = \\\\sum _ { t = 1 } ^ { T } \\\\sum _ { v = 1 } ^ { V } { \\\\cal M } _ { v } ^ { \\\\mathrm { ( e y e l i d \\\\, ) } } \\\\left( \\\\left\\\\| \\\\hat { h } _ { t, v } - x _ { t, v } \\\\right\\\\| ^ { 2 } \\\\right)', '\\\\lim _ { x \\\\rightarrow \\\\frac { 1 } { 4 } } \\\\frac { 1 - 4 ^ { x - \\\\frac { 1 } { 4 } } } { 1 - 4 x }']\n"
     ]
    }
   ],
   "source": [
    "#! pip install transformers>=4.37.0 pillow optimum[onnxruntime]\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor\n",
    "from optimum.onnxruntime import ORTModelForVision2Seq\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('breezedeus/pix2text-mfr')\n",
    "model = ORTModelForVision2Seq.from_pretrained('breezedeus/pix2text-mfr', use_cache=False)\n",
    "\n",
    "def download_img(url):\n",
    "    response = requests.get(url)\n",
    "    image_file = BytesIO(response.content)\n",
    "    return Image.open(image_file).convert('RGB')\n",
    "\n",
    "\n",
    "image_fps = [\n",
    "    'https://raw.githubusercontent.com/breezedeus/Pix2Text/main/docs/examples/formula.jpg',\n",
    "    'https://raw.githubusercontent.com/breezedeus/Pix2Text/main/docs/examples/math-formula-42.png',\n",
    "]\n",
    "images = [download_img(fp) for fp in image_fps]\n",
    "pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "# print(f'pixel_values', pixel_values)\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "print(f'generated_ids: {generated_ids}, \\ngenerated text: {generated_text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e913e-a7a5-4266-bd19-39f144a074f2",
   "metadata": {},
   "source": [
    "Code latex:\n",
    "$$\n",
    "{ \\cal L } _ { \\mathrm { e y e l i d \\, } } = \\sum _ { t = 1 } ^ { T } \\sum _ { v = 1 } ^ { V } { \\cal M } _ { v } ^ { \\mathrm { ( e y e l i d \\, ) } } \\left( \\left\\| \\hat { h } _ { t, v } - x _ { t, v } \\right\\| ^ { 2 } \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lim _ { x \\rightarrow \\frac { 1 } { 4 } } \\frac { 1 - 4 ^ { x - \\frac { 1 } { 4 } } } { 1 - 4 x }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "639ebadd-bc37-484b-9a8c-5a7152f955b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderConfig {\n",
      "  \"architectures\": [\n",
      "    \"VisionEncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"activation_dropout\": 0.0,\n",
      "    \"activation_function\": \"relu\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"classifier_dropout\": 0.0,\n",
      "    \"cross_attention_hidden_size\": 384,\n",
      "    \"d_model\": 256,\n",
      "    \"decoder_attention_heads\": 8,\n",
      "    \"decoder_ffn_dim\": 1024,\n",
      "    \"decoder_layerdrop\": 0.0,\n",
      "    \"decoder_layers\": 6,\n",
      "    \"dropout\": 0.1,\n",
      "    \"init_std\": 0.02,\n",
      "    \"is_decoder\": true,\n",
      "    \"layernorm_embedding\": true,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"model_type\": \"trocr\",\n",
      "    \"scale_embedding\": true,\n",
      "    \"tie_word_embeddings\": false,\n",
      "    \"use_cache\": false,\n",
      "    \"use_learned_position_embeddings\": true,\n",
      "    \"vocab_size\": 1200\n",
      "  },\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"encoder\": {\n",
      "    \"attention_probs_dropout_prob\": 0.0,\n",
      "    \"encoder_stride\": 16,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.0,\n",
      "    \"hidden_size\": 384,\n",
      "    \"image_size\": 384,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 1536,\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"model_type\": \"deit\",\n",
      "    \"num_attention_heads\": 6,\n",
      "    \"num_channels\": 3,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"patch_size\": 16,\n",
      "    \"pooler_act\": \"tanh\",\n",
      "    \"pooler_output_size\": 384,\n",
      "    \"qkv_bias\": true\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"model_type\": \"vision-encoder-decoder\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd68aa13-3d29-4150-8857-ef408fe4ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderConfig {\n",
      "  \"architectures\": [\n",
      "    \"VisionEncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"activation_dropout\": 0.0,\n",
      "    \"activation_function\": \"relu\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"classifier_dropout\": 0.0,\n",
      "    \"cross_attention_hidden_size\": 384,\n",
      "    \"d_model\": 256,\n",
      "    \"decoder_attention_heads\": 8,\n",
      "    \"decoder_ffn_dim\": 1024,\n",
      "    \"decoder_layerdrop\": 0.0,\n",
      "    \"decoder_layers\": 6,\n",
      "    \"dropout\": 0.1,\n",
      "    \"init_std\": 0.02,\n",
      "    \"is_decoder\": true,\n",
      "    \"layernorm_embedding\": true,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"model_type\": \"trocr\",\n",
      "    \"scale_embedding\": true,\n",
      "    \"tie_word_embeddings\": false,\n",
      "    \"use_cache\": false,\n",
      "    \"use_learned_position_embeddings\": true,\n",
      "    \"vocab_size\": 1200\n",
      "  },\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"encoder\": {\n",
      "    \"attention_probs_dropout_prob\": 0.0,\n",
      "    \"encoder_stride\": 16,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.0,\n",
      "    \"hidden_size\": 384,\n",
      "    \"image_size\": 384,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 1536,\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"model_type\": \"deit\",\n",
      "    \"num_attention_heads\": 6,\n",
      "    \"num_channels\": 3,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"patch_size\": 16,\n",
      "    \"pooler_act\": \"tanh\",\n",
      "    \"pooler_output_size\": 384,\n",
      "    \"qkv_bias\": true\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"model_type\": \"vision-encoder-decoder\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.55.0\",\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c95d555a-aaf6-48df-89a0-0523dbcf797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx2pytorch\n",
      "  Downloading onnx2pytorch-0.5.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from onnx2pytorch) (2.8.0a0+5228986c39.nv25.5)\n",
      "Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from onnx2pytorch) (1.18.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from onnx2pytorch) (0.22.0a0)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/venv/lib/python3.12/site-packages (from onnx>=1.6.0->onnx2pytorch) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /opt/venv/lib/python3.12/site-packages (from onnx>=1.6.0->onnx2pytorch) (4.25.8)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /opt/venv/lib/python3.12/site-packages (from onnx>=1.6.0->onnx2pytorch) (4.14.1)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.12/site-packages (from torch>=1.4.0->onnx2pytorch) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/venv/lib/python3.12/site-packages (from torch>=1.4.0->onnx2pytorch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/venv/lib/python3.12/site-packages (from torch>=1.4.0->onnx2pytorch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/lib/python3.12/site-packages (from torch>=1.4.0->onnx2pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/venv/lib/python3.12/site-packages (from torch>=1.4.0->onnx2pytorch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/venv/lib/python3.12/site-packages (from torch>=1.4.0->onnx2pytorch) (79.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.4.0->onnx2pytorch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.9.0->onnx2pytorch) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/venv/lib/python3.12/site-packages (from jinja2->torch>=1.4.0->onnx2pytorch) (3.0.2)\n",
      "Downloading onnx2pytorch-0.5.1-py3-none-any.whl (46 kB)\n",
      "Installing collected packages: onnx2pytorch\n",
      "Successfully installed onnx2pytorch-0.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnx2pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b629f6cc-eb6b-4e2e-b7a2-675d9913aa4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ORTModelForVision2Seq' object has no attribute 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx2pytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConvertModel\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pytorch_model = \u001b[43mConvertModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(pytorch_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/onnx2pytorch/convert/model.py:116\u001b[39m, in \u001b[36mConvertModel.__init__\u001b[39m\u001b[34m(self, onnx_model, batch_dim, experimental, debug, enable_pruning)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.debug = debug\n\u001b[32m    114\u001b[39m \u001b[38;5;28mself\u001b[39m.enable_pruning = enable_pruning\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28mself\u001b[39m.input_names = get_inputs_names(\u001b[43monnx_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m)\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m.output_names = get_outputs_names(onnx_model.graph)\n\u001b[32m    118\u001b[39m opset_version = onnx_model.opset_import[\u001b[32m0\u001b[39m].version\n",
      "\u001b[31mAttributeError\u001b[39m: 'ORTModelForVision2Seq' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx2pytorch import ConvertModel\n",
    "\n",
    "pytorch_model = ConvertModel(model)\n",
    "\n",
    "print(pytorch_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05be42eb-5d67-40a1-ad2d-81ea4ea02a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/hub/models--breezedeus--pix2text-mfr/snapshots/bea257edb2653f2ae413b084f2ac0e8299d08df0\n"
     ]
    }
   ],
   "source": [
    "print(model.model_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f9b0df4-c0af-45aa-824d-4730d1235358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16K\n",
      "drwxr-xr-x 2 root root 4.0K Oct 15 06:51 .\n",
      "drwxr-xr-x 3 root root 4.0K Oct 15 06:50 ..\n",
      "lrwxrwxrwx 1 root root   52 Oct 15 06:50 config.json -> ../../blobs/c6f828ccd5f3e8781dc7c7a715bc4b8f80ff41bc\n",
      "lrwxrwxrwx 1 root root   76 Oct 15 06:51 decoder_model.onnx -> ../../blobs/fd0f92d7a012f3dae41e1ac79421aea0ea888b5a66cb3f9a004e424f82f3daed\n",
      "lrwxrwxrwx 1 root root   76 Oct 15 06:51 encoder_model.onnx -> ../../blobs/bd8d5c322792e9ec45793af5569e9748f82a3d728a9e00213dbfc56c1486f37d\n",
      "lrwxrwxrwx 1 root root   52 Oct 15 06:51 generation_config.json -> ../../blobs/a3d09b3add4319b3c2d0ca15011f3618109df47b\n",
      "lrwxrwxrwx 1 root root   52 Oct 15 06:50 preprocessor_config.json -> ../../blobs/c2bbec3a0dbefdd3ecce8a82458664790ce39b20\n",
      "lrwxrwxrwx 1 root root   52 Oct 15 06:50 special_tokens_map.json -> ../../blobs/b1879d702821e753ffe4245048eee415d54a9385\n",
      "lrwxrwxrwx 1 root root   52 Oct 15 06:50 tokenizer.json -> ../../blobs/c07aa39397f33b7822ef84e435e911a70a4ce303\n",
      "lrwxrwxrwx 1 root root   52 Oct 15 06:50 tokenizer_config.json -> ../../blobs/bdfa7cd6ca95d1662e765144547e7952869bed33\n"
     ]
    }
   ],
   "source": [
    "!ls -alh /root/.cache/huggingface/hub/models--breezedeus--pix2text-mfr/snapshots/bea257edb2653f2ae413b084f2ac0e8299d08df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27cc5497-ecef-47f7-a2f1-1588350f5d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvertModel(\n",
      "  (Conv_/embeddings/patch_embeddings/projection/Conv_output_0): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (Shape_/embeddings/patch_embeddings/Shape_output_0): Shape()\n",
      "  (Constant_/embeddings/patch_embeddings/Constant_output_0): Constant(constant=tensor([0]))\n",
      "  (Constant_/embeddings/patch_embeddings/Constant_1_output_0): Constant(constant=tensor([0]))\n",
      "  (Constant_/embeddings/patch_embeddings/Constant_2_output_0): Constant(constant=tensor([2]))\n",
      "  (Slice_/embeddings/patch_embeddings/Slice_output_0): Slice()\n",
      "  (Constant_/embeddings/patch_embeddings/Constant_3_output_0): Constant(constant=tensor([-1]))\n",
      "  (Reshape_/embeddings/patch_embeddings/Reshape_output_0): Reshape(shape=None)\n",
      "  (Transpose_/embeddings/patch_embeddings/Transpose_output_0): Transpose()\n",
      "  (Shape_/embeddings/Shape_output_0): Shape()\n",
      "  (Constant_/embeddings/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/embeddings/Gather_output_0): Gather()\n",
      "  (Unsqueeze_/embeddings/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Constant_/embeddings/Constant_1_output_0): Constant(constant=tensor([-1]))\n",
      "  (Constant_/embeddings/Constant_2_output_0): Constant(constant=tensor([-1]))\n",
      "  (Constant_/embeddings/Constant_3_output_0): Constant(constant=tensor([-1]))\n",
      "  (Reshape_/embeddings/Reshape_output_0): Reshape(shape=None)\n",
      "  (Shape_/embeddings/Shape_1_output_0): Shape()\n",
      "  (ConstantOfShape_/embeddings/ConstantOfShape_output_0): ConstantOfShape(constant=tensor([1]))\n",
      "  (Constant_/embeddings/Constant_4_output_0): Constant(constant=-1)\n",
      "  (Mul_/embeddings/Mul_output_0): mul()\n",
      "  (Equal_/embeddings/Equal_output_0): mul()\n",
      "  (Where_/embeddings/Where_output_0): Where()\n",
      "  (Expand_/embeddings/Expand_output_0): Expand()\n",
      "  (Unsqueeze_/embeddings/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/embeddings/Constant_5_output_0): Constant(constant=tensor([-1]))\n",
      "  (Constant_/embeddings/Constant_6_output_0): Constant(constant=tensor([-1]))\n",
      "  (Constant_/embeddings/Constant_7_output_0): Constant(constant=tensor([-1]))\n",
      "  (Reshape_/embeddings/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Shape_/embeddings/Shape_2_output_0): Shape()\n",
      "  (ConstantOfShape_/embeddings/ConstantOfShape_1_output_0): ConstantOfShape(constant=tensor([1]))\n",
      "  (Constant_/embeddings/Constant_8_output_0): Constant(constant=-1)\n",
      "  (Mul_/embeddings/Mul_1_output_0): mul()\n",
      "  (Equal_/embeddings/Equal_1_output_0): mul()\n",
      "  (Where_/embeddings/Where_1_output_0): Where()\n",
      "  (Expand_/embeddings/Expand_1_output_0): Expand()\n",
      "  (Add_/embeddings/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.0/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.0/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.0/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.0/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.0/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.0/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.0/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.0/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.0/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.0/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.0/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.0/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.0/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.0/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.0/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.0/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.0/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.0/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.0/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.0/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.0/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.0/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.0/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.0/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.0/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.0/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.0/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.0/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.0/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.0/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.0/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.0/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.0/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.0/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.0/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.0/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.0/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.0/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.0/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.0/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.0/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.0/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.1/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.1/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.1/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.1/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.1/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.1/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.1/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.1/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.1/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.1/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.1/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.1/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.1/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.1/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.1/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.1/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.1/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.1/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.1/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.1/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.1/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.1/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.1/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.1/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.1/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.1/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.1/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.1/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.1/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.1/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.1/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.1/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.1/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.1/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.1/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.1/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.1/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.1/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.1/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.1/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.1/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.1/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.2/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.2/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.2/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.2/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.2/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.2/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.2/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.2/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.2/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.2/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.2/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.2/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.2/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.2/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.2/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.2/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.2/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.2/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.2/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.2/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.2/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.2/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.2/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.2/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.2/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.2/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.2/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.2/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.2/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.2/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.2/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.2/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.2/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.2/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.2/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.2/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.2/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.2/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.2/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.2/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.2/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.2/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.3/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.3/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.3/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.3/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.3/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.3/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.3/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.3/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.3/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.3/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.3/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.3/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.3/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.3/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.3/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.3/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.3/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.3/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.3/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.3/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.3/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.3/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.3/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.3/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.3/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.3/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.3/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.3/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.3/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.3/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.3/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.3/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.3/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.3/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.3/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.3/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.3/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.3/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.3/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.3/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.3/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.3/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.4/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.4/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.4/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.4/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.4/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.4/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.4/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.4/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.4/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.4/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.4/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.4/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.4/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.4/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.4/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.4/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.4/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.4/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.4/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.4/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.4/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.4/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.4/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.4/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.4/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.4/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.4/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.4/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.4/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.4/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.4/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.4/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.4/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.4/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.4/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.4/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.4/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.4/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.4/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.4/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.4/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.4/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.5/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.5/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.5/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.5/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.5/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.5/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.5/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.5/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.5/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.5/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.5/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.5/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.5/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.5/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.5/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.5/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.5/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.5/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.5/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.5/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.5/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.5/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.5/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.5/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.5/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.5/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.5/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.5/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.5/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.5/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.5/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.5/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.5/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.5/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.5/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.5/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.5/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.5/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.5/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.5/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.5/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.5/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.6/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.6/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.6/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.6/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.6/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.6/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.6/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.6/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.6/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.6/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.6/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.6/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.6/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.6/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.6/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.6/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.6/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.6/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.6/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.6/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.6/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.6/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.6/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.6/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.6/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.6/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.6/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.6/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.6/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.6/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.6/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.6/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.6/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.6/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.6/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.6/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.6/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.6/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.6/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.6/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.6/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.6/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.6/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.6/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.6/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.6/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.6/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.6/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.7/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.7/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.7/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.7/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.7/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.7/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.7/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.7/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.7/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.7/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.7/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.7/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.7/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.7/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.7/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.7/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.7/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.7/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.7/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.7/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.7/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.7/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.7/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.7/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.7/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.7/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.7/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.7/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.7/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.7/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.7/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.7/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.7/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.7/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.7/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.7/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.7/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.7/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.7/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.7/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.7/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.7/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.7/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.7/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.7/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.7/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.7/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.7/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.8/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.8/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.8/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.8/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.8/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.8/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.8/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.8/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.8/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.8/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.8/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.8/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.8/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.8/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.8/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.8/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.8/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.8/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.8/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.8/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.8/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.8/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.8/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.8/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.8/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.8/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.8/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.8/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.8/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.8/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.8/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.8/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.8/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.8/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.8/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.8/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.8/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.8/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.8/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.8/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.8/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.8/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.8/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.8/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.8/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.8/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.8/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.8/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.9/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.9/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.9/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.9/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.9/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.9/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.9/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.9/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.9/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.9/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.9/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.9/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.9/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.9/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.9/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.9/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.9/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.9/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.9/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.9/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.9/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.9/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.9/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.9/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.9/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.9/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.9/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.9/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.9/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.9/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.9/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.9/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.9/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.9/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.9/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.9/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.9/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.9/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.9/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.9/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.9/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.9/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.9/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.9/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.9/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.9/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.9/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.9/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.10/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.10/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.10/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.10/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.10/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.10/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.10/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.10/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.10/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.10/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.10/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.10/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.10/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.10/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.10/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.10/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.10/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.10/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.10/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.10/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.10/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.10/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.10/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.10/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.10/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.10/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.10/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.10/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.10/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.10/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.10/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.10/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.10/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.10/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.10/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.10/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.10/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.10/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.10/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.10/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.10/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.10/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.10/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.10/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.10/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.10/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.10/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.10/output/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.11/layernorm_before/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.11/layernorm_before/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.11/layernorm_before/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.11/layernorm_before/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.11/layernorm_before/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.11/layernorm_before/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.11/layernorm_before/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.11/layernorm_before/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.11/layernorm_before/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.11/attention/attention/query/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (MatMul_/encoder/layer.11/attention/attention/key/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_output_0): Gather()\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_1_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_1_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_1_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_1_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_2_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_3_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.11/attention/attention/Reshape_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.11/attention/attention/value/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_2_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_4_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_2_output_0): Gather()\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_3_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_5_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_3_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_2_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_3_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_6_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_7_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.11/attention/attention/Reshape_1_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.11/attention/attention/Transpose_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_4_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_8_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_4_output_0): Gather()\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_5_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_9_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_5_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_4_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_5_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_10_output_0): Constant(constant=tensor([6]))\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_11_output_0): Constant(constant=tensor([64]))\n",
      "  (Reshape_/encoder/layer.11/attention/attention/Reshape_2_output_0): Reshape(shape=None)\n",
      "  (Transpose_/encoder/layer.11/attention/attention/Transpose_1_output_0): Transpose()\n",
      "  (Transpose_/encoder/layer.11/attention/attention/Transpose_2_output_0): Transpose()\n",
      "  (MatMul_/encoder/layer.11/attention/attention/MatMul_output_0): MatMul()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_12_output_0): Constant(constant=8.0)\n",
      "  (Div_/encoder/layer.11/attention/attention/Div_output_0): Div()\n",
      "  (Softmax_/encoder/layer.11/attention/attention/Softmax_output_0): Softmax(dim=3)\n",
      "  (MatMul_/encoder/layer.11/attention/attention/MatMul_1_output_0): MatMul()\n",
      "  (Transpose_/encoder/layer.11/attention/attention/Transpose_3_output_0): Transpose()\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_6_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_13_output_0): Constant(constant=0)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_6_output_0): Gather()\n",
      "  (Shape_/encoder/layer.11/attention/attention/Shape_7_output_0): Shape()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_14_output_0): Constant(constant=1)\n",
      "  (Gather_/encoder/layer.11/attention/attention/Gather_7_output_0): Gather()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_6_output_0): Unsqueeze()\n",
      "  (Unsqueeze_/encoder/layer.11/attention/attention/Unsqueeze_7_output_0): Unsqueeze()\n",
      "  (Constant_/encoder/layer.11/attention/attention/Constant_15_output_0): Constant(constant=tensor([384]))\n",
      "  (Reshape_/encoder/layer.11/attention/attention/Reshape_3_output_0): Reshape(shape=None)\n",
      "  (MatMul_/encoder/layer.11/attention/output/dense/Add_output_0): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.11/Add_output_0): Add()\n",
      "  (Sub_/encoder/layer.11/layernorm_after/Sub_output_0): mul()\n",
      "  (Constant_/encoder/layer.11/layernorm_after/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/encoder/layer.11/layernorm_after/Pow_output_0): mul()\n",
      "  (Constant_/encoder/layer.11/layernorm_after/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/encoder/layer.11/layernorm_after/Add_output_0): Add()\n",
      "  (Sqrt_/encoder/layer.11/layernorm_after/Sqrt_output_0): mul()\n",
      "  (Div_/encoder/layer.11/layernorm_after/Div_output_0): Div()\n",
      "  (Mul_/encoder/layer.11/layernorm_after/Mul_output_0): mul()\n",
      "  (Add_/encoder/layer.11/layernorm_after/Add_1_output_0): Add()\n",
      "  (MatMul_/encoder/layer.11/intermediate/dense/Add_output_0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (Constant_/encoder/layer.11/intermediate/intermediate_act_fn/Constant_output_0): Constant(constant=1.4142135381698608)\n",
      "  (Div_/encoder/layer.11/intermediate/intermediate_act_fn/Div_output_0): Div()\n",
      "  (Erf_/encoder/layer.11/intermediate/intermediate_act_fn/Erf_output_0): mul()\n",
      "  (Constant_/encoder/layer.11/intermediate/intermediate_act_fn/Constant_1_output_0): Constant(constant=1.0)\n",
      "  (Add_/encoder/layer.11/intermediate/intermediate_act_fn/Add_output_0): Add()\n",
      "  (Mul_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_output_0): mul()\n",
      "  (Constant_/encoder/layer.11/intermediate/intermediate_act_fn/Constant_2_output_0): Constant(constant=0.5)\n",
      "  (Mul_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0): mul()\n",
      "  (MatMul_/encoder/layer.11/output/dense/Add_output_0): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (Add_/encoder/layer.11/output/Add_output_0): Add()\n",
      "  (Sub_/layernorm/Sub_output_0): mul()\n",
      "  (Constant_/layernorm/Constant_output_0): Constant(constant=2.0)\n",
      "  (Pow_/layernorm/Pow_output_0): mul()\n",
      "  (Constant_/layernorm/Constant_1_output_0): Constant(constant=9.999999960041972e-13)\n",
      "  (Add_/layernorm/Add_output_0): Add()\n",
      "  (Sqrt_/layernorm/Sqrt_output_0): mul()\n",
      "  (Div_/layernorm/Div_output_0): Div()\n",
      "  (Mul_/layernorm/Mul_output_0): mul()\n",
      "  (Add_last_hidden_state): Add()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx2pytorch import ConvertModel\n",
    "\n",
    "onnx_path = \"/root/.cache/huggingface/hub/models--breezedeus--pix2text-mfr/snapshots/bea257edb2653f2ae413b084f2ac0e8299d08df0/encoder_model.onnx\"\n",
    "onnx_model = onnx.load(onnx_path)  # Đây là đối tượng ModelProto\n",
    "pytorch_model = ConvertModel(onnx_model)\n",
    "\n",
    "print(pytorch_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74327bf5-defe-453e-a350-39cac74cf1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_/embeddings/patch_embeddings/projection/Conv_output_0.weight torch.Size([384, 3, 16, 16])\n",
      "Conv_/embeddings/patch_embeddings/projection/Conv_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.0/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.0/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.0/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.0/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.0/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.0/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.0/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.0/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.0/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.0/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.0/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.0/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.1/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.1/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.1/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.1/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.1/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.1/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.1/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.1/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.1/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.1/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.1/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.1/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.2/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.2/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.2/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.2/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.2/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.2/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.2/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.2/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.2/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.2/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.2/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.2/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.3/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.3/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.3/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.3/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.3/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.3/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.3/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.3/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.3/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.3/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.3/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.3/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.4/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.4/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.4/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.4/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.4/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.4/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.4/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.4/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.4/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.4/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.4/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.4/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.5/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.5/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.5/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.5/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.5/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.5/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.5/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.5/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.5/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.5/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.5/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.5/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.6/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.6/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.6/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.6/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.6/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.6/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.6/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.6/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.6/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.6/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.6/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.6/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.7/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.7/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.7/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.7/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.7/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.7/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.7/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.7/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.7/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.7/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.7/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.7/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.8/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.8/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.8/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.8/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.8/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.8/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.8/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.8/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.8/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.8/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.8/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.8/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.9/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.9/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.9/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.9/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.9/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.9/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.9/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.9/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.9/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.9/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.9/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.9/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.10/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.10/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.10/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.10/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.10/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.10/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.10/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.10/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.10/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.10/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.10/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.10/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.11/attention/attention/query/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.11/attention/attention/query/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.11/attention/attention/key/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.11/attention/attention/key/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.11/attention/attention/value/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.11/attention/attention/value/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.11/attention/output/dense/Add_output_0.weight torch.Size([384, 384])\n",
      "MatMul_/encoder/layer.11/attention/output/dense/Add_output_0.bias torch.Size([384])\n",
      "MatMul_/encoder/layer.11/intermediate/dense/Add_output_0.weight torch.Size([1536, 384])\n",
      "MatMul_/encoder/layer.11/intermediate/dense/Add_output_0.bias torch.Size([1536])\n",
      "MatMul_/encoder/layer.11/output/dense/Add_output_0.weight torch.Size([384, 1536])\n",
      "MatMul_/encoder/layer.11/output/dense/Add_output_0.bias torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in pytorch_model.named_parameters():\n",
    "    # if i > 1: \n",
    "    #     break\n",
    "    print(name, param.shape)\n",
    "    # print(param.data)\n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ebff3-65b4-48b3-bc91-94c24d77cc65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
